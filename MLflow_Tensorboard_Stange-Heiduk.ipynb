{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mlflow & Tensorboard\n",
    "\n",
    "Name: Justin Stange-Heiduk  \n",
    "Matrikelnummer: [Deine Matrikelnummer]  \n",
    "Universität: AKAD   \n",
    "Kurs: B.Sc Data Science    \n",
    "Dozent: Dr. Martin Prause   \n",
    "Beginn: 03.02.2025  \n",
    "Orientiert an: https://keras.io/guides/transfer_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\n",
    "from datetime import datetime\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeiner Teil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 files belonging to 2 classes.\n",
      "Using 79 files for training.\n",
      "Found 98 files belonging to 2 classes.\n",
      "Using 19 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Bildverzeichnis\n",
    "data_dir = \"simpsons\"\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size_par = 5\n",
    "\n",
    "# Datensatz laden\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir, seed=123, labels=\"inferred\", label_mode='int',\n",
    "    validation_split=0.2, subset=\"training\",\n",
    "    image_size=(img_height, img_width), batch_size=batch_size_par)\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir, seed=123, labels=\"inferred\", label_mode='int',\n",
    "    validation_split=0.2, subset=\"validation\",\n",
    "    image_size=(img_height, img_width), batch_size=batch_size_par)\n",
    "\n",
    "# Dataset optimieren\n",
    "train_dataset = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Modell laden\n",
    "vgg_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Schichten einfrieren\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 8s 458ms/step - loss: 6.4009 - accuracy: 0.6962 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 7s 444ms/step - loss: 1.4274 - accuracy: 0.8861 - val_loss: 5.5365e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 7s 412ms/step - loss: 0.2710 - accuracy: 0.9620 - val_loss: 0.0951 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/simpsons_classifier_mlflow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/simpsons_classifier_mlflow\\assets\n",
      "2025/02/17 09:18:17 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Justi\\AppData\\Local\\Temp\\tmpn2l_aipo\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Justi\\AppData\\Local\\Temp\\tmpn2l_aipo\\model\\data\\model\\assets\n",
      "2025/02/17 09:18:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run abgeschlossen: 5edeef09937b4372856e4676e466d24f mit Namen: run_simpson_klassifikation_3\n",
      "Modell gespeichert unter: saved_model/simpsons_classifier_mlflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Zähler für Run-Nummer bestimmen\n",
    "experiment = mlflow.get_experiment_by_name(\"Simpsons_Classification\")\n",
    "if experiment:\n",
    "    run_count = len(mlflow.search_runs(experiment_ids=[experiment.experiment_id]))\n",
    "else:\n",
    "    run_count = 0  # Falls Experiment noch nicht existiert\n",
    "\n",
    "run_name = f\"run_simpson_klassifikation_{run_count + 1}\"\n",
    "\n",
    "# MLflow Experiment starten\n",
    "mlflow.set_experiment(\"Simpsons_Classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    \n",
    "    # Definierte Parameter für das Experiment\n",
    "    experiment_params = {\n",
    "        \"filters\": 64,\n",
    "        \"Dense_neurons\": 128,\n",
    "        \"Dropout_rate\": 0.4,\n",
    "        \"epochs\": 3,\n",
    "        \"batch_size\": batch_size_par,\n",
    "        \"loss_function\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"rmsprop\",\n",
    "        \"metrics\": [\"accuracy\"]\n",
    "    }\n",
    "\n",
    "    # Logging des Run-Namens als Parameter\n",
    "    mlflow.log_param(\"run_name\", run_name)\n",
    "\n",
    "    # Zusätzliche Schichten definieren\n",
    "    x = vgg_model.output\n",
    "    x = Conv2D(experiment_params[\"filters\"], kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(experiment_params[\"Dense_neurons\"], activation='relu')(x)\n",
    "    x = Dropout(experiment_params[\"Dropout_rate\"])(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Modell erstellen\n",
    "    custom_model = Model(vgg_model.input, x)\n",
    "\n",
    "    # Schichten einfrieren\n",
    "    for layer in custom_model.layers[:18]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Modell kompilieren\n",
    "    custom_model.compile(\n",
    "        loss=experiment_params[\"loss_function\"], \n",
    "        optimizer=experiment_params[\"optimizer\"], \n",
    "        metrics=experiment_params[\"metrics\"]\n",
    "    )\n",
    "\n",
    "    # MLflow Logging für alle Parameter\n",
    "    mlflow.log_params(experiment_params)\n",
    "\n",
    "    # Training starten\n",
    "    history = custom_model.fit(train_dataset, epochs=experiment_params[\"epochs\"], validation_data=validation_dataset)\n",
    "\n",
    "    # Metriken loggen\n",
    "    for epoch, (train_loss, train_acc, val_loss, val_acc) in enumerate(zip(\n",
    "        history.history[\"loss\"], history.history[\"accuracy\"], \n",
    "        history.history[\"val_loss\"], history.history[\"val_accuracy\"])):\n",
    "\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "\n",
    "    # Modell speichern und loggen\n",
    "    model_path = \"saved_model/simpsons_classifier_mlflow\"\n",
    "    custom_model.save(model_path)\n",
    "    mlflow.tensorflow.log_model(custom_model, \"model_simpsons_mlflow\")\n",
    "\n",
    "    # # Modell in der Model Registry speichern\n",
    "    # model_uri = f\"runs:/{run.info.run_id}/model_simpsons_mlflow\"\n",
    "    # registered_model_name = \"Simpsons_Classifier\"\n",
    "    # model_version = mlflow.register_model(model_uri, registered_model_name)\n",
    "\n",
    "    print(f\"Run abgeschlossen: {run.info.run_id} mit Namen: {run_name}\")\n",
    "    print(f\"Modell gespeichert unter: {model_path}\")\n",
    "    #print(f\"Modell registriert als: {registered_model_name}, Version: {model_version.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 9s 507ms/step - loss: 3.5938 - accuracy: 0.6835 - val_loss: 1.4100 - val_accuracy: 0.7895\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 8s 481ms/step - loss: 2.0268 - accuracy: 0.8734 - val_loss: 0.1590 - val_accuracy: 0.8947\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 8s 510ms/step - loss: 0.0589 - accuracy: 0.9747 - val_loss: 0.1281 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_simpsons_tensorboard_adam\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_simpsons_tensorboard_adam\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training abgeschlossen mit Optimizer: adam\n",
      "TensorBoard-Logs gespeichert unter: tensorboard_logs\\run_1_adam_20250217-091841\n",
      "Modell gespeichert unter: models\\model_simpsons_tensorboard_adam\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 9s 489ms/step - loss: 5.6407 - accuracy: 0.6203 - val_loss: 2.2883 - val_accuracy: 0.7368\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 7s 461ms/step - loss: 0.8850 - accuracy: 0.9367 - val_loss: 1.4922 - val_accuracy: 0.8421\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 7s 464ms/step - loss: 1.1866 - accuracy: 0.9367 - val_loss: 0.0254 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_simpsons_tensorboard_rmsprop\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_simpsons_tensorboard_rmsprop\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training abgeschlossen mit Optimizer: rmsprop\n",
      "TensorBoard-Logs gespeichert unter: tensorboard_logs\\run_2_rmsprop_20250217-091908\n",
      "Modell gespeichert unter: models\\model_simpsons_tensorboard_rmsprop\n"
     ]
    }
   ],
   "source": [
    "# Definierte fixe Parameter für das Experiment\n",
    "experiment_params = {\n",
    "    \"filters\": 64,\n",
    "    \"Dense_neurons\": 256,\n",
    "    \"Dropout_rate\": 0.5,\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 5,\n",
    "    \"loss_function\": \"binary_crossentropy\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "\n",
    "# Definierte Hyperparameter (Optimizer)\n",
    "HPARAMS = {\"optimizer\": hp.HParam(\"optimizer\", hp.Discrete([\"adam\", \"rmsprop\"]))}\n",
    "\n",
    "# Runs für verschiedene Optimizer durchführen\n",
    "for i, optimizer_name in enumerate(HPARAMS[\"optimizer\"].domain.values, start=1):\n",
    "\n",
    "    # Eindeutiger Run-Name für TensorBoard\n",
    "    run_name = f\"run_{i}_{optimizer_name}\"\n",
    "\n",
    "    # Eindeutiges TensorBoard-Log-Verzeichnis für jeden Run\n",
    "    log_dir = os.path.join(\"tensorboard_logs\", f\"{run_name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    " \n",
    "    # Hyperparameter-Logging (Speichert den verwendeten Optimizer)\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams({HPARAMS[\"optimizer\"]: optimizer_name})  \n",
    "\n",
    "    # Zusätzliche Schichten definieren\n",
    "    x = vgg_model.output\n",
    "    x = Conv2D(experiment_params[\"filters\"], kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(experiment_params[\"Dense_neurons\"], activation='relu')(x)\n",
    "    x = Dropout(experiment_params[\"Dropout_rate\"])(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Modell erstellen\n",
    "    custom_model = Model(vgg_model.input, x)\n",
    "\n",
    "    # Schichten einfrieren\n",
    "    for layer in custom_model.layers[:18]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Optimizer auswählen\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "    # Modell kompilieren\n",
    "    custom_model.compile(\n",
    "        loss=experiment_params[\"loss_function\"], \n",
    "        optimizer=optimizer, \n",
    "        metrics=experiment_params[\"metrics\"]\n",
    "    )\n",
    "\n",
    "    # TensorBoard-Callbacks einrichten\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True,\n",
    "    update_freq='epoch',  # Verhindert zu häufiges Logging\n",
    "    profile_batch=0        # Deaktiviert das automatische Erstellen von Unterlogs für `train` und `validation`\n",
    ")\n",
    "\n",
    "    profiler_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, profile_batch=1)  \n",
    "\n",
    "\n",
    "    # Funktion zur Speicherung von Eingabebildern in TensorBoard\n",
    "    def log_images(dataset, writer, step):\n",
    "        for images, labels in dataset.take(1):  \n",
    "            # Bilder von [0,255] auf [0,1] normalisieren\n",
    "            images = images / 255.0\n",
    "\n",
    "            with writer.as_default():\n",
    "                tf.summary.image(\"Training Images\", images, step=step, max_outputs=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # TensorBoard-Writer für Bilder\n",
    "    image_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "\n",
    "    # Training starten\n",
    "    history = custom_model.fit(\n",
    "        train_dataset, epochs=experiment_params[\"epochs\"], \n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=[tensorboard_callback, profiler_callback]\n",
    "    )\n",
    "\n",
    "    # Eingabebilder in TensorBoard speichern\n",
    "    log_images(train_ds, image_writer, step=experiment_params[\"epochs\"])\n",
    "\n",
    "    # Modell speichern mit einzigartigem Namen für jeden Optimizer\n",
    "    model_path = os.path.join(\"models\", f\"model_simpsons_tensorboard_{optimizer_name}\")\n",
    "    custom_model.save(model_path)\n",
    "\n",
    "    print(f\"Training abgeschlossen mit Optimizer: {optimizer_name}\")\n",
    "    print(f\"TensorBoard-Logs gespeichert unter: {log_dir}\")\n",
    "    print(f\"Modell gespeichert unter: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvTf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
